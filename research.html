<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Rafa Pages - Volograms Co-Founder & CEO</title>

  <meta name="author" content="Rafa Pages">
  <meta name="description" content="Rafa Pages research activities">
  <meta name="keywords" content="volumetric capture, volumetric video, AR, VR, hologram, photogrammetry, volograms" />
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Open Graph -->
	<meta property="og:title" content="Rafa Pages - Volograms Co-Founder & CEO" />
	<meta property="og:type" content="website" />
	<meta property="og:description" content="Learn more about my research" />
	<meta property="og:image" content="https://rafapages.com/img/rafa_electro_new_logo.jpg" />
	<meta property="og:url" content="https://rafapages.com" />
	<meta property="twitter:card" content="summary_large_image" />
	<meta property="twitter:image" content="https://rafapages.com/img/rafa_electro_new_logo.jpg" />



  <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet" type="text/css">
  <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">

  <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link rel="stylesheet" type="text/css" href="css/stylesheet.css">
  <link href="css/agency.min.css" rel="stylesheet">

  <link rel="icon" href="rp.ico">
</head>

<body>
  <header id="Main" class="bg-white text-black">

    <div class="container">
      <div class="row">
        <div class="col-lg-12 text-center">
          <a href="http://rafapages.com">
          <img src="img/rafa_electro_new_logo.jpg" class="img-fluid" alt="Vologram progression">
        </a>
        </div>
      </div>
    </div>

  </header>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Rafa Pagés</name>
              </p>
              <p>I am a staff research scientist at <a href="https://ai.google/research">Google Research</a>, where I work on computer vision and machine learning.
              </p>
              <p>
                At Google I've worked on <a href="https://ai.googleblog.com/2020/12/portrait-light-enhancing-portrait.html">Portrait Light</a>, <a href="https://ai.googleblog.com/2014/04/lens-blur-in-new-google-camera-app.html">Lens Blur</a>, <a href="https://ai.googleblog.com/2014/10/hdr-low-light-and-high-dynamic-range.html">HDR+</a>, <a href="https://www.google.com/get/cardboard/jump/">Jump</a>, <a href="https://ai.googleblog.com/2017/10/portrait-mode-on-pixel-2-and-pixel-2-xl.html">Portrait Mode</a>, and <a href="https://www.youtube.com/watch?v=JSnB06um5r4">Glass</a>. I did my PhD at <a href="http://www.eecs.berkeley.edu/">UC Berkeley</a>, where I was advised by <a href="http://www.cs.berkeley.edu/~malik/">Jitendra Malik</a> and funded by the <a href="http://www.nsfgrfp.org/">NSF GRFP</a>. I did my bachelors at the <a href="http://cs.toronto.edu">University of Toronto</a>.
                I've received the <a href="https://www2.eecs.berkeley.edu/Students/Awards/15/">C.V. Ramamoorthy Distinguished Research Award</a> and the <a href="https://www.thecvf.com/?page_id=413#YRA">PAMI Young Researcher Award</a>.
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <img style="width:100%;max-width:100%" alt="profile photo" src="img/rafa_blurred_bg.jpg" class="hoverZoomLink">
            </td>
          </tr>
        </tbody></table> -->
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <h1 class="text-center">Research</h1>
              <p>
                Before founding Volograms, I was a Postdoctoral Research Fellow at <a href="https://v-sense.scss.tcd.ie/" target="_blank">V-SENSE</a>, <a href="https://tcd.ie" target="
                ">Trinity College Dublin</a>, where I was advised by <a href="https://scholar.google.com/citations?user=HZRejX4AAAAJ&hl=en" target="_blank">Prof. Aljosa Smolic</a>. I did my PhD at <a href="http://gti.ssr.upm.es/" target="_blank">GTI</a>, <a href="https://www.upm.es/" target="_blank">Universidad Politécnica de Madrid</a>, under the supervision of <a href="https://scholar.google.com/citations?user=l6L1ytIAAAAJ&hl=en" target="_blank">Prof. Francisco Morán</a>.
              </p>
              <p>
              My research interests are computer vision, 3D reconstruction, volumetric video and image processing. I’m especially interested in the reconstruction of the shape an appearance of human models.
                Representative papers are <span class="highlight">highlighted</span>.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td>
              <h3>Publications</h3>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="vologan_stop()" onmouseover="vologan_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='vologan_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/vologan_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/vologan.jpg' width="160">
              </div>
              <script type="text/javascript">
                function vologan_start() {
                  document.getElementById('facemirror_image').style.opacity = "1";
                }
                function vologan_stop() {
                  document.getElementById('facemirror_image').style.opacity = "0";
                }
                vologan_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2207.09204" target="_blank">
                <papertitle>VoloGAN: Adversarial Domain Adaptation for Synthetic Depth Data</papertitle>
              </a>
              <br>
              <a>Sascha Kirch</a>,
              <a>Sergio Arnaldo</a>,
              <a>Sergio Martín</a>,
              <strong>Rafael Pagés</strong>
              <br>
              <em>Arxiv</em>, 2022
              <br>
              <p>We present VoloGAN, an adversarial domain adaptation network that translates synthetic RGB-D images of a high-quality 3D model of a person, into RGB-D images that could be generated with a consumer depth sensor.
              </p>
              </td>
          </tr>


          <!-- Paper -->
          <tr onmouseout="dataset_stop()" onmouseover="dataset_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dataset_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/dataset.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/dataset.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dataset_start() {
                  document.getElementById('dataset_image').style.opacity = "1";
                }
                function dataset_stop() {
                  document.getElementById('dataset_image').style.opacity = "0";
                }
                dataset_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://dx.doi.org/10.13140/RG.2.2.24235.31529/1" target="_blank">
                <papertitle>Volograms & V-SENSE Volumetric Video Dataset</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Emin Zerman</a>,
              <a>Konstantinos Amplianitis</a>,
              <a>Jan Ondrej</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>ISO/IEC JTC1/SC29/WG07 MPEG2021/m56767</em>, 2021
              <br>
              <a href="https://volograms.com/research-datasets" target="_blank">project page</a>
              <p>This paper describes the Volograms & V-SENSE Volumetric Video Dataset which is made publicly available to help said research and standardisation efforts.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="resol_stop()" onmouseover="resol_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='facemirror_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/facemirror_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/face-mirror.jpg' width="160">
              </div>
              <script type="text/javascript">
                function resol_start() {
                  document.getElementById('facemirror_image').style.opacity = "1";
                }
                function resol_stop() {
                  document.getElementById('facemirror_image').style.opacity = "0";
                }
                resol_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/6116055" target="_blank">
                <papertitle>Influence of Mirror Therapy (Specular Face Software) on Electromyographic Behavior of the Facial Muscles for Facial Palsy</papertitle>
              </a>
              <br>
              <a>Alfonso Gil-Martínez</a>,
              <a>Sergio Lerma-Lara</a>,
              <a>Alfredo Hernando-Jorge</a>,
              <a>Ana Campos-Vegas</a>,
              <a>Audrey Aceval</a>,
              <strong>Rafael Pagés</strong>,
              <a>Francisco Morán</a>,
              <a>Hector Beltran-Alacreu</a>
              <br>
              <em>Brain Sciences, 11(7), 930</em>, 2021
              <br>
              <p>Using facial detection and tracking to simulate “mirror therapy” to help patients with facial paralysis.
              </p>
              </td>
          </tr>
          <!-- Paper -->
          <tr onmouseout="autotrack_stop()" onmouseover="autotrack_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='autotrack_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/autotrack.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/autotrack.jpg' width="160">
              </div>
              <script type="text/javascript">
                function autotrack_start() {
                  document.getElementById('autotrack_image').style.opacity = "1";
                }
                function autotrack_stop() {
                  document.getElementById('autotrack_image').style.opacity = "0";
                }
                autotrack_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2020/12/WACV_2021_preprint_compressed.pdf" target="_blank">
                <papertitle>Autonomous Tracking For Volumetric Video Sequences</papertitle>
              </a>
              <br>
              <a>Matt Moynihan</a>,
              <a>Susana Ruano</a>,
              <strong>Rafael Pagés</strong>,
              <a>Aljosa Smolic</a>
              <br>
              <em>WACV</em>, 2021
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/6dof/autonomous-tracking-for-volumetric-video-sequences/" target="_blank">project page</a> /
              <a href="https://www.youtube.com/watch?v=JwO2obk0tJM">video</a>
              <p>A robust, autonomous method for tracking volumetric sequences which can detect missing geometry and propagate user edits.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="selfreg_stop()" onmouseover="selfreg_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='selfreg_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/selfreg.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/selfreg.jpg' width="160">
              </div>
              <script type="text/javascript">
                function selfreg_start() {
                  document.getElementById('selfreg_image').style.opacity = "1";
                }
                function selfreg_stop() {
                  document.getElementById('selfreg_image').style.opacity = "0";
                }
                selfreg_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2020/05/mm2020Cloud_compressed.pdf" target="_blank">
                <papertitle>A Self-regulating Spatio-Temporal Filter for Volumetric Video Point Clouds</papertitle>
              </a>
              <br>
              <a>Matt Moynihan</a>,
              <strong>Rafael Pagés</strong>,
              <a>Aljosa Smolic</a>
              <br>
              <em>Computer Vision, Imaging and Computer Graphics Theory and Applications, Springer</em>, 2020
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/6dof/spatio-temporal-upsampling-for-free-viewpoint-video-point-clouds/" target="_blank">project page</a> /
              <a href="https://link.springer.com/chapter/10.1007%2F978-3-030-41590-7_16">book chapter</a>
              <p>A self-regulating filter that is capable of performing accurate upsampling of dynamic point cloud data sequences captured using wide-baseline multi-view camera setups.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="inf_stop()" onmouseover="inf_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/inflation.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/inf1.jpg' width="160">
              </div>
              <script type="text/javascript">
                function inf_start() {
                  document.getElementById('inf_image').style.opacity = "1";
                }

                function inf_stop() {
                  document.getElementById('inf_image').style.opacity = "0";
                }
                inf_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2019/12/CVMP2019.pdf" target="_blank">
                <papertitle>Augmenting Hand-Drawn Art with Global Illumination Effects through Surface Inflation</papertitle>
              </a>
              <br>
              <a>Matis Hudon</a>,
              <a>Sebastian Lutz</a>,
              <strong>Rafael Pagés</strong>,
              <a>Aljosa Smolic</a>
              <br>
              <em>European Conference on Visual Media Production (CVMP)</em>, 2019
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/augmenting-hand-drawn-art-with-global-illumination-effects-through-surface-inflation/" target="_blank">project page</a>
              <p>
              A method for augmenting hand-drawn characters and creatures with global illumination effects.
             </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="toon_stop()" onmouseover="toon_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='toon_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/toon.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/toon.jpg' width="160">
              </div>
              <script type="text/javascript">
                function toon_start() {
                  document.getElementById('toon_image').style.opacity = "1";
                }

                function toon_stop() {
                  document.getElementById('toon_image').style.opacity = "0";
                }
                toon_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/pii/S2590148619300032" target="_blank">
                <papertitle>2DToonShade: A stroke based toon shading system</papertitle>
              </a>
              <br>
              <a>Matis Hudon</a>,
              <a>Mairead Grogan</a>,
              <strong>Rafael Pagés</strong>,
              <a>Jan Ondrej</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>Computers & Graphics: X Volume 1</em>, 2019
              <br>
              <p>
              A semi-automatic method for creating shades and self-shadows in cel animation.</p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="visapp_stop()" onmouseover="visapp_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='visapp_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/visapp.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/visapp.jpg' width="160">
              </div>
              <script type="text/javascript">
                function visapp_start() {
                  document.getElementById('visapp_image').style.opacity = "1";
                }
                function visapp_stop() {
                  document.getElementById('visapp_image').style.opacity = "0";
                }
                visapp_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2019/05/VISIGRAPP_2019camera-ready.pdf" target="_blank">
                <papertitle>Spatio-Temporal Upsampling for Free Viewpoint Video Point Clouds</papertitle>
              </a>
              <br>
              <a>Matt Moynihan</a>,
              <strong>Rafael Pagés</strong>,
              <a>Aljosa Smolic</a>
              <br>
              <em>Computer Vision, Imaging and Computer Graphics Theory and Applications, Springer</em>, 2019
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/6dof/spatio-temporal-upsampling-for-free-viewpoint-video-point-clouds/" target="_blank">project page</a>
              <p>An approach to upsampling point cloud sequences captured through a wide baseline camera
setup in a spatio-temporally consistent manner.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr bgcolor="#ebedff" onmouseout="fvv_stop()" onmouseover="fvv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='fvv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/fvv.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/fvv.jpg' width="160">
              </div>
              <script type="text/javascript">
                function fvv_start() {
                  document.getElementById('fvv_image').style.opacity = "1";
                }
                function fvv_stop() {
                  document.getElementById('fvv_image').style.opacity = "0";
                }
                fvv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S1047320318300683" target="_blank">
                <papertitle>Affordable Content Creation for Free-viewpoint Video and VR/AR Applications</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Konstantinos Amplianitis</a>,
              <a>David Monaghan</a>,
              <a>Jan Ondrej</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>Journal of Visual Communication and Image Representation, Volume 53</em>, 2018
              <br>
              Best paper award &#127894;
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/6dof/affordable-content-creation-for-free-viewpoint-video-and-vr-ar-applications/" target="_blank">project page</a> /
              <a href="https://www.youtube.com/watch?v=KY1375qlhQo&feature=emb_title" target="_blank">video</a>
              <p>A scalable pipeline for Free-Viewpoint Video (FVV) content creation, considering also visualisation in Augmented Reality and Virtual Reality.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="swift_stop()" onmouseover="swift_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='swift_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/swift.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/swift.jpg' width="160">
              </div>
              <script type="text/javascript">
                function swift_start() {
                  document.getElementById('swift_image').style.opacity = "1";
                }
                function swift_stop() {
                  document.getElementById('swift_image').style.opacity = "0";
                }
                swift_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://v-sense.scss.tcd.ie/wp-content/uploads/2019/01/ODwyer2018_Chapter_JonathanSwiftAugmentedRealityA-2.pdf" target="_blank">
                <papertitle>Jonathan Swift: Augmented Reality Application for Trinity Library’s Long Room</papertitle>
              </a>
              <br>
              <a>Néill O'Dwyer</a>,
              <a>Jan Ondrej</a>,
              <strong>Rafael Pagés</strong>,
              <a>Konstantinos Amplianitis</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>International Conference on Interactive Digital Storytelling</em>, 2018
              <br>
              <a href="https://v-sense.scss.tcd.ie/creative-experiments/jonathan-swift-in-vr-ar-long-room-project/" target="_blank">project page</a>
              <p>The interactive prototype visualises Jonathan Swift in AR, allowing the user to be immersed in world of cultural heritage.
              </p>
            </td>
          </tr>


          <!-- Paper -->
          <tr onmouseout="bplay_stop()" onmouseover="bplay_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='bplay_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/bplay.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/bplay.jpg' width="160">
              </div>
              <script type="text/javascript">
                function bplay_start() {
                  document.getElementById('bplay_image').style.opacity = "1";
                }
                function bplay_stop() {
                  document.getElementById('bplay_image').style.opacity = "0";
                }
                bplay_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.mitpressjournals.org/doi/abs/10.1162/leon_a_01721" target="_blank">
                <papertitle>Samuel Beckett in VR: Exploring narrative using free viewpoint video</papertitle>
              </a>
              <br>
              <a>Néill O'Dwyer</a>,
              <a>Nicholas Johnson</a>,
              <strong>Rafael Pagés</strong>,
              <a>Jan Ondrej</a>,
              <a>Konstantinos Amplianitis</a>,
              <a>Enda Bates</a>,
              <a>David Monaghan</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>ACM SIGGRAPH - Leonardo, MIT Press</em>, 2018
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/mr-play-trilogy/" target="_blank">project page</a> /
              <a href="https://www.youtube.com/watch?v=SKZ43EMEiI4&feature=emb_title" target="_blank">video</a>
              <p>Virtual Play is a reinterpretation of Play, with a view to engaging a 21st Century viewership that is increasingly accessing content via VR.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="deepnormal_stop()" onmouseover="deepnormal_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='deepnormal_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/deepnormal.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/deepnormal.jpg' width="160">
              </div>
              <script type="text/javascript">
                function deepnormal_start() {
                  document.getElementById('deepnormal_image').style.opacity = "1";
                }
                function deepnormal_stop() {
                  document.getElementById('deepnormal_image').style.opacity = "0";
                }
                deepnormal_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://openaccess.thecvf.com/content_eccv_2018_workshops/w16/html/Hudon_Deep_Normal_Estimation_for_Automatic_Shading_of_Hand-Drawn_Characters_ECCVW_2018_paper.html" target="_blank">
                <papertitle>Deep Normal Estimation for Automatic Shading of Hand-Drawn Characters</papertitle>
              </a>
              <br>
              <a>Matis Hudon</a>,
              <a>Mairead Grogan</a>,
              <strong>Rafael Pagés</strong>,
              <a>Aljosa Smolic</a>
              <br>
              <em>ECCV</em>, 2018
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/vfx-animation/deep-normal-estimation-for-automatic-shading-of-hand-drawn-characters/" target="_blank">project page</a> /
              <a href="https://www.youtube.com/watch?v=1tZ-y0PzV8g" target="_blank">video</a> /
              <a href="https://github.com/V-Sense/DeepNormals" target="_blank">code</a>
              <p>A new fully automatic pipeline for generating shading effects on hand-drawn characters.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="cel_stop()" onmouseover="cel_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='cel_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/cel.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/cel.jpg' width="160">
              </div>
              <script type="text/javascript">
                function cel_start() {
                  document.getElementById('cel_image').style.opacity = "1";
                }
                function cel_stop() {
                  document.getElementById('cel_image').style.opacity = "0";
                }
                cel_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/3229147.3229148" target="_blank">
                <papertitle>2D Shading for Cel Animation</papertitle>
              </a>
              <br>
              <a>Matis Hudon</a>,
              <strong>Rafael Pagés</strong>,
              <a>Mairead Grogan</a>,
              <a>Jan Ondrej</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>Expressive Graphics</em>, 2018
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/vfx-animation/2d-shading-for-cel-animation/" target="_blank">project page</a> /
              <a href="https://www.youtube.com/watch?v=4pFufShSt0c" target="_blank">video</a>
              <p>A semi-automatic method for creating shades and self-shadows in cel animation.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="beckett_stop()" onmouseover="beckett_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='beckett_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/beckett.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/beckett.jpg' width="160">
              </div>
              <script type="text/javascript">
                function beckett_start() {
                  document.getElementById('beckett_image').style.opacity = "1";
                }
                function beckett_stop() {
                  document.getElementById('beckett_image').style.opacity = "0";
                }
                beckett_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/8088501" target="_blank">
                <papertitle>Virtual Play in Free-viewpoint Video: Reinterpreting Samuel Beckett for Virtual Reality</papertitle>
              </a>
              <br>
              <a>Néill O'Dwyer</a>,
              <a>Nicholas Johnson</a>,
              <a>Enda Bates</a>,
              <strong>Rafael Pagés</strong>,
              <a>Jan Ondrej</a>,
              <a>Konstantinos Amplianitis</a>,
              <a>David Monaghan</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>IEEE ISMAR</em>, 2017
              <br>
              <a href="https://v-sense.scss.tcd.ie/research/mr-play-trilogy/" target="_blank">project page</a> /
              <a href="https://www.youtube.com/watch?v=SKZ43EMEiI4&feature=emb_title" target="_blank">video</a>
              <p>Virtual Play is a reinterpretation of Play, with a view to engaging a 21st Century viewership that is increasingly accessing content via VR.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="radar_stop()" onmouseover="radar_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='radar_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/radar.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/radar.jpg' width="160">
              </div>
              <script type="text/javascript">
                function radar_start() {
                  document.getElementById('radar_image').style.opacity = "1";
                }
                function radar_stop() {
                  document.getElementById('radar_image').style.opacity = "0";
                }
                radar_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/7933257" target="_blank">
                <papertitle>Simulation framework for a 3D high-resolution imaging radar at 300 GHz with a scattering model based on rendering techniques</papertitle>
              </a>
              <br>
              <a>Guillermo Ortiz-Jiménez</a>,
              <a>Federico García-Rial</a>,
              <a>Luis A. Úbeda-Medina</a>,
              <strong>Rafael Pagés</strong>,
              <a>Narciso García</a>,
              <a>Jesús Grajal</a>
              <br>
              <em>IEEE Transactions on Terahertz Science and Technology, Volume 7</em>, 2017
              <br>
              <p>A simulation framework for a 3D high-resolution imaging radar at 300 GHz with mechanical scanning.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="ffeat_stop()" onmouseover="ffeat_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ffeat_image'><img src='research/ffeat_after.jpg' width="160"></div>
                <img src='research/ffeat_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ffeat_start() {
                  document.getElementById('ffeat_image').style.opacity = "1";
                }
                function ffeat_stop() {
                  document.getElementById('ffeat_image').style.opacity = "0";
                }
                ffeat_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/7820978" target="_blank">
                <papertitle>Fast Feature Matching for Detailed Point Cloud Generation</papertitle>
              </a>
              <br>
              <a>Daniel Berjón</a>,
              <strong>Rafael Pagés</strong>,
              <a>Francisco Morán</a>
              <br>
              <em>International Conference on Image Processing Theory, Tools and Applications (IPTA)</em>, 2016
              <br>
              <p>We propose a technique based on epipolar geometry restrictions to significantly cut down on processing time and an efficient implementation thereof on a GPU.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr bgcolor="#ebedff" onmouseout="ssmv_stop()" onmouseover="ssmv_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='ssmv_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/ssmv.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/ssmv.jpg' width="160">
              </div>
              <script type="text/javascript">
                function ssmv_start() {
                  document.getElementById('ssmv_image').style.opacity = "1";
                }
                function ssmv_stop() {
                  document.getElementById('ssmv_image').style.opacity = "0";
                }
                ssmv_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/cgf.12508" target="_blank">
                <papertitle>Seamless, Static Multi‐Texturing of 3D Meshes</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Daniel Berjón</a>,
              <a>Francisco Morán</a>,
              <a>Narciso García</a>
              <br>
              <em>Computer Graphics Forum, Volume 34</em>, 2015
              <br>
              <a href="https://github.com/rafapages/SSMVtex" target="_blank">code</a>
              <p>We present a static multi‐texturing system yielding a seamless texture atlas calculated by combining the colour information from several photos from the same subject covering most of its surface.
              </p>
            </td>
          </tr>


          <!-- Paper -->
          <tr onmouseout="splash_stop()" onmouseover="splash_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='splash_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/splash_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/splash.jpg' width="160">
              </div>
              <script type="text/javascript">
                function splash_start() {
                  document.getElementById('splash_image').style.opacity = "1";
                }
                function splash_stop() {
                  document.getElementById('splash_image').style.opacity = "0";
                }
                splash_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/2775292.2775320" target="_blank">
                <papertitle>SPLASH: a Hybrid 3D Modeling/Rendering Approach Mixing Splats and Meshes</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Sergio García</a>,
              <a>Daniel Berjón</a>,
              <a>Francisco Morán</a>
              <br>
              <em>Web3D</em>, 2015
              <br>
              <p>We propose a hybrid 3D modeling and rendering approach called SPLASH to combine the modeling flexibility and robustness of SPLAts together with the rendering simplicity and maturity of meSHes.
              </p>
            </td>
          </tr>


          <!-- Paper -->
          <tr onmouseout="splats_stop()" onmouseover="splats_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='splats_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/splats.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/splats.jpg' width="160">
              </div>
              <script type="text/javascript">
                function splats_start() {
                  document.getElementById('splats_image').style.opacity = "1";
                }
                function splats_stop() {
                  document.getElementById('splats_image').style.opacity = "0";
                }
                splats_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/2775292.2782779" target="_blank">
                <papertitle>Textured splat-based point clouds for rendering in handheld devices</papertitle>
              </a>
              <br>
              <a>Sergio García</a>,
              <strong>Rafael Pagés</strong>,
              <a>Daniel Berjón</a>,
              <a>Francisco Morán</a>
              <br>
              <em>Web3D</em>, 2015
              <br>
              <p>We propose a novel technique for modeling and rendering a 3D point cloud obtained from a set of photographs of a real 3D scene as a set of textured elliptical splats.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr bgcolor="#ebedff" onmouseout="humans_stop()" onmouseover="humans_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='humans_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/humans.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/humans.jpg' width="160">
              </div>
              <script type="text/javascript">
                function humans_start() {
                  document.getElementById('humans_image').style.opacity = "1";
                }
                function humans_stop() {
                  document.getElementById('humans_image').style.opacity = "0";
                }
                humans_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.sciencedirect.com/science/article/abs/pii/S0923596513000957" target="_blank">
                <papertitle>Automatic system for virtual human reconstruction with 3D mesh multi-texturing and facial enhancement</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Daniel Berjón</a>,
              <a>Francisco Morán</a>
              <br>
              <em>Signal Processing: Image Communication, Volume 28 </em>, 2013
              <br>
              <p>We present a fully automatic low-cost system for generating animatable and statically multi-textured avatars of real people captured with several standard cameras.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="facemerge_stop()" onmouseover="facemerge_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='facemerge_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/facemerge.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/facemerge.jpg' width="160">
              </div>
              <script type="text/javascript">
                function facemerge_start() {
                  document.getElementById('facemerge_image').style.opacity = "1";
                }
                function facemerge_stop() {
                  document.getElementById('facemerge_image').style.opacity = "0";
                }
                facemerge_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/6365448" target="_blank">
                <papertitle>3D facial merging for virtual human reconstruction</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Daniel Berjón</a>,
              <a>Francisco Morán</a>
              <br>
              <em>3DTV Conference</em>, 2012
              <br>
              <p>A technique to merge a VH-based 3D mesh of a reconstructed humanoid and the depth data of its face, captured by a single structured light projector.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="refined_stop()" onmouseover="refined_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='refined_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/refined.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/refined.jpg' width="160">
              </div>
              <script type="text/javascript">
                function refined_start() {
                  document.getElementById('refined_image').style.opacity = "1";
                }
                function refined_stop() {
                  document.getElementById('refined_image').style.opacity = "0";
                }
                refined_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.spiedigitallibrary.org/conference-proceedings-of-spie/8290/82900J/Refined-facial-disparity-maps-for-automatic-creation-of-3D-avatars/10.1117/12.908259.short?SSO=1" target="_blank">
                <papertitle>Refined facial disparity maps for automatic creation of 3D avatars</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Francisco Morán</a>,
              <a>Luis Salgado</a>,
              <a>Daniel Berjón</a>
              <br>
              <em>IS&T/SPIE Electronic Imaging</em>, 2012
              <br>
              <p>We propose a new method to automatically refine a facial disparity map obtained with standard cameras and under conventional illumination conditions by using a smart combination of traditional computer vision and 3D graphics techniques.
              </p>
            </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="resol_stop()" onmouseover="resol_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='resol_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/resol_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/resol.jpg' width="160">
              </div>
              <script type="text/javascript">
                function resol_start() {
                  document.getElementById('resol_image').style.opacity = "1";
                }
                function resol_stop() {
                  document.getElementById('resol_image').style.opacity = "0";
                }
                resol_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/6116055" target="_blank">
                <papertitle>Multi-resolution texture coding for multi-resolution 3D meshes</papertitle>
              </a>
              <br>
              <a>David Fuentes</a>,
              <strong>Rafael Pagés</strong>,
              <a>Francisco Morán</a>
              <br>
              <em>VCIP</em>, 2011
              <br>
              <p>We present an innovative system to encode and transmit textured multi-resolution 3D meshes in a progressive way, with no need to send several texture images, one for each mesh LOD.
              </p>
              </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="facelift_stop()" onmouseover="facelift_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='inerf_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/facelift.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/facelift.jpg' width="160">
              </div>
              <script type="text/javascript">
                function facelift_start() {
                  document.getElementById('facelift_image').style.opacity = "1";
                }
                function facelift_stop() {
                  document.getElementById('facelift_image').style.opacity = "0";
                }
                facelift_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/abstract/document/6079374" target="_blank">
                <papertitle>Face lift surgery for reconstructed virtual humans</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Sergio Arnaldo</a>,
              <a>Francisco Morán</a>
              <br>
              <em>International Conference on Cyberworlds</em>, 2011
              <br>
              <a href="https://github.com/rafapages/face-morpher" target="_blank">code</a>
              <p>We introduce an innovative, semi-automatic method to transform low resolution facial meshes into high definition ones, based on the tailoring of a generic, neutral human head model.
              </p>
              </td>
          </tr>

          <!-- Paper -->
          <tr onmouseout="item_stop()" onmouseover="item_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='item_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/item.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/item.jpg' width="160">
              </div>
              <script type="text/javascript">
                function item_start() {
                  document.getElementById('item_image').style.opacity = "1";
                }
                function item_stop() {
                  document.getElementById('item_image').style.opacity = "0";
                }
                item_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://dl.acm.org/doi/abs/10.1145/2010425.2010431" target="_blank">
                <papertitle>ITEM: inter-texture error measurement for 3D meshes</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>David Fuentes</a>,
              <a>Francisco Morán</a>
              <br>
              <em>Web3D</em>, 2011
              <br>
              <p>We introduce a simple and innovative method to compare any two texture maps, regardless of their sizes, aspect ratios, or even masks, as long as they are both meant to be mapped onto the same 3D mesh.
              </p>
              </td>
              </tr>

          <!-- Paper -->
          <tr onmouseout="composition_stop()" onmouseover="composition_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='composition_image'><video  width=100% height=100% muted autoplay loop>
                <source src="research/composition.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='research/composition.jpg' width="160">
              </div>
              <script type="text/javascript">
                function composition_start() {
                  document.getElementById('composition_image').style.opacity = "1";
                }
                function composition_stop() {
                  document.getElementById('composition_image').style.opacity = "0";
                }
                composition_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://diglib.eg.org/handle/10.2312/LocalChapterEvents.ItalChap.ItalianChapConf2010.123-128" target="_blank">
                <papertitle>Composition of Texture Atlases for 3D Mesh Multi-texturing</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Sergio Arnaldo</a>,
              <a>Francisco Morán</a>
              <br>
              <em>Eurographics</em>, 2010
              <br>
              <p>We introduce an automatic technique for mapping onto a 3D triangle mesh a high resolution texture synthesized from several pictures taken by standard cameras surrounding the object.
              </p>
              </td>
          </tr>


        </tbody>
      </table>



        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td>
              <h3>Patents</h3>
            </td>
          </tr>

          <!-- Patent -->
          <tr onmouseout="patent1_stop()" onmouseover="patent1_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='patent3_image'><img src='research/p3.jpg' width="160"></div>
                <img src='research/p3.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US20220245885A1/en" target="_blank">
                <papertitle>Volumetric Imaging</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Jan Ondrej</a>,
              <a>Konstantinos Amplianitis</a>,
              <a>Sergio Arnaldo</a>,
              <a>Valeria Olyunina</a>
              <br>
              <em>US20220245885A1, EP Application EP21154369.9</em>

              <p>A method for generating a moving volumetric image of a moving object from data recorded by a user-held device comprising: acquiring, from the user-held device, video and depth data of the moving object, and pose data; and communicating the acquired data to a computing module.
              </p>
            </td>
          </tr>

          <!-- Patent -->
          <tr onmouseout="patent1_stop()" onmouseover="patent1_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='patent1_image'><img src='research/p1.jpg' width="160"></div>
                <img src='research/p1.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/US11348267B2/en" target="_blank">
                <papertitle>Method and apparatus for generating a three-dimensional model</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Konstantinos Amplianitis</a>,
              <a>David Monaghan</a>,
              <a>Jan Ondrej</a>,
              <a>Aljosa Smolic</a>
              <br>
              <em>US20200320727B2, EP Application PCT/EP2018/086331.</em>

              <p>A method comprising providing a plurality of images of a scene captured by a plurality of image capturing devices.
              </p>
            </td>
          </tr>

          <!-- Patent -->
          <tr onmouseout="patent2_stop()" onmouseover="patent2_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='patent2_image'><img src='research/p2.jpg' width="160"></div>
                <img src='research/p2.jpg' width="160">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://patents.google.com/patent/EP2852932A1/en" target="_blank">
                <papertitle>A method and a system for generating a realistic 3d reconstruction model for an object or being</papertitle>
              </a>
              <br>
              <strong>Rafael Pagés</strong>,
              <a>Daniel Berjón</a>,
              <a>Sergio Arnaldo</a>,
              <a>Francisco Morán</a>,
              <a>Tomas Montserrat Mora</a>,
              <a>Julien Quelen</a>,
              <a>Oscar Divorra Escoda</a>,
              <a>Christian Ferran Bernstrom</a>
              <br>
              <em>US Application US20150178988A1, EP Application EP2852932A1, WO Application WO2013174671A1</em>
              <p>A method for generating a realistic 3D reconstruction model for an object or being.
              </p>
            </td>
          </tr>


        </tbody>
      </table>




  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
           <tr>
             <td style="padding:0px">
               <br>
               <p style="text-align:center;font-size:small;">
                 This page was "stolen" from <a href="https://jonbarron.info" target="_blank">Jon Barron's website</a>. You can find the <a href="https://github.com/jonbarron/jonbarron_website" target="_blank">source code here</a>.
               </p>
             </td>
           </tr>
         </tbody></table>
       </td>
     </tr>
   </table>
  <!-- Footer -->
  <footer>
    <div class="container">
      <div class="row">
        <div class="col-md-4">
        </div>
        <div class="col-md-4">
          <ul class="list-inline social-buttons">
            <li class="list-inline-item">
              <a href="https://twitter.com/rafamolone" target="_blank">
                <i class="fa fa-twitter"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://linkedin.com/in/rafapages/en" target="_blank">
                <i class="fa fa-linkedin"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://instagram.com/rafapages" target="_blank">
                <i class="fa fa-instagram"></i>
              </a>
            </li>
            <li class="list-inline-item">
              <a href="https://scholar.google.com/citations?user=V5G2vyIAAAAJ&hl=en&oi=ao" target="_blank">
                <i class="fa fa-book"></i>
              </a>
            </li>
          </ul>
        </div>
      </div>
    </div>
    <div class="container">
      <div class="row justify-content-center">
        <span class="copyright">Copyright &copy; Rafael Pagés</span>
      </div>
    </div>
  </footer>

</body>

</html>
